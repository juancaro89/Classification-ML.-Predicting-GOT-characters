{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5809e2b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1946, 25)\n",
      "Index(['S.No', 'name', 'title', 'culture', 'dateOfBirth', 'mother', 'father',\n",
      "       'heir', 'house', 'spouse', 'book1_A_Game_Of_Thrones',\n",
      "       'book2_A_Clash_Of_Kings', 'book3_A_Storm_Of_Swords',\n",
      "       'book4_A_Feast_For_Crows', 'book5_A_Dance_with_Dragons',\n",
      "       'isAliveMother', 'isAliveFather', 'isAliveHeir', 'isAliveSpouse',\n",
      "       'isMarried', 'isNoble', 'age', 'numDeadRelations', 'popularity',\n",
      "       'isAlive'],\n",
      "      dtype='object')\n",
      "Index(['S.No', 'name', 'title', 'culture', 'dateOfBirth', 'mother', 'father',\n",
      "       'heir', 'house', 'spouse', 'book1', 'book2', 'book3', 'book4', 'book5',\n",
      "       'isAliveMother', 'isAliveFather', 'isAliveHeir', 'isAliveSpouse',\n",
      "       'isMarried', 'isNoble', 'age', 'numDeadRelations', 'popularity',\n",
      "       'isAlive'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S.No</th>\n",
       "      <th>name</th>\n",
       "      <th>title</th>\n",
       "      <th>culture</th>\n",
       "      <th>dateOfBirth</th>\n",
       "      <th>mother</th>\n",
       "      <th>father</th>\n",
       "      <th>heir</th>\n",
       "      <th>house</th>\n",
       "      <th>spouse</th>\n",
       "      <th>...</th>\n",
       "      <th>isAliveMother</th>\n",
       "      <th>isAliveFather</th>\n",
       "      <th>isAliveHeir</th>\n",
       "      <th>isAliveSpouse</th>\n",
       "      <th>isMarried</th>\n",
       "      <th>isNoble</th>\n",
       "      <th>age</th>\n",
       "      <th>numDeadRelations</th>\n",
       "      <th>popularity</th>\n",
       "      <th>isAlive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Viserys II Targaryen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rhaenyra Targaryen</td>\n",
       "      <td>Daemon Targaryen</td>\n",
       "      <td>Aegon IV Targaryen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>0.605351</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Walder Frey</td>\n",
       "      <td>Lord of the Crossing</td>\n",
       "      <td>Rivermen</td>\n",
       "      <td>208.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House Frey</td>\n",
       "      <td>Perra Royce</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.896321</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Addison Hill</td>\n",
       "      <td>Ser</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House Swyft</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.267559</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Aemma Arryn</td>\n",
       "      <td>Queen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House Arryn</td>\n",
       "      <td>Viserys I Targaryen</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.183946</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Sylva Santagar</td>\n",
       "      <td>Greenstone</td>\n",
       "      <td>Dornish</td>\n",
       "      <td>276.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House Santagar</td>\n",
       "      <td>Eldon Estermont</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   S.No                  name                 title   culture  dateOfBirth  \\\n",
       "0     1  Viserys II Targaryen                   NaN       NaN          NaN   \n",
       "1     2           Walder Frey  Lord of the Crossing  Rivermen        208.0   \n",
       "2     3          Addison Hill                   Ser       NaN          NaN   \n",
       "3     4           Aemma Arryn                 Queen       NaN         82.0   \n",
       "4     5        Sylva Santagar            Greenstone   Dornish        276.0   \n",
       "\n",
       "               mother            father                heir           house  \\\n",
       "0  Rhaenyra Targaryen  Daemon Targaryen  Aegon IV Targaryen             NaN   \n",
       "1                 NaN               NaN                 NaN      House Frey   \n",
       "2                 NaN               NaN                 NaN     House Swyft   \n",
       "3                 NaN               NaN                 NaN     House Arryn   \n",
       "4                 NaN               NaN                 NaN  House Santagar   \n",
       "\n",
       "                spouse  ...  isAliveMother  isAliveFather  isAliveHeir  \\\n",
       "0                  NaN  ...            1.0            0.0          0.0   \n",
       "1          Perra Royce  ...            NaN            NaN          NaN   \n",
       "2                  NaN  ...            NaN            NaN          NaN   \n",
       "3  Viserys I Targaryen  ...            NaN            NaN          NaN   \n",
       "4      Eldon Estermont  ...            NaN            NaN          NaN   \n",
       "\n",
       "   isAliveSpouse  isMarried  isNoble   age  numDeadRelations  popularity  \\\n",
       "0            NaN          0        0   NaN                11    0.605351   \n",
       "1            1.0          1        1  97.0                 1    0.896321   \n",
       "2            NaN          0        1   NaN                 0    0.267559   \n",
       "3            0.0          1        1  23.0                 0    0.183946   \n",
       "4            1.0          1        1  29.0                 0    0.043478   \n",
       "\n",
       "   isAlive  \n",
       "0        0  \n",
       "1        1  \n",
       "2        1  \n",
       "3        0  \n",
       "4        1  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import requiered libraries\n",
    "import pandas            as pd                       # data science essentials\n",
    "import matplotlib.pyplot as plt                      # data visualization\n",
    "import seaborn           as sns                      # enhanced data viz\n",
    "import numpy             as np\n",
    "from sklearn.model_selection import train_test_split # train-test split\n",
    "from sklearn.linear_model import LogisticRegression  # logistic regression\n",
    "import statsmodels.formula.api as smf                # logistic regression\n",
    "from sklearn.metrics import confusion_matrix         # confusion matrix\n",
    "from sklearn.metrics import roc_auc_score            # auc score\n",
    "from sklearn.neighbors import KNeighborsClassifier   # KNN for classification\n",
    "from sklearn.neighbors import KNeighborsRegressor    # KNN for regression\n",
    "from sklearn.preprocessing import StandardScaler     # standard scaler\n",
    "from sklearn.tree import DecisionTreeClassifier      # classification trees\n",
    "from sklearn.tree import plot_tree                   # tree plots\n",
    "import gender_guesser.detector as gender # guess gender based on (given) name\n",
    "\n",
    "\n",
    "#PAth of the excel file I'm going to use for the project\n",
    "file = './GOT_character_predictions.xlsx'\n",
    "\n",
    "#Read the file for the project\n",
    "\n",
    "GOT = pd.read_excel(io=file)\n",
    "\n",
    "(GOT.head(n=5))\n",
    "\n",
    "print (GOT.shape)\n",
    "print(GOT.columns)\n",
    "(GOT.head(n=5))\n",
    "\n",
    "# relabeling columns\n",
    "GOT.columns = ['S.No', 'name', 'title', 'culture', 'dateOfBirth', 'mother', 'father',\n",
    "       'heir', 'house', 'spouse', 'book1','book2', 'book3','book4', 'book5',\n",
    "       'isAliveMother', 'isAliveFather', 'isAliveHeir', 'isAliveSpouse',\n",
    "       'isMarried', 'isNoble', 'age', 'numDeadRelations', 'popularity',\n",
    "       'isAlive']\n",
    "\n",
    "\n",
    "# checking results\n",
    "print (GOT.columns)\n",
    "(GOT.head(n=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215cfe9a",
   "metadata": {},
   "source": [
    "Categorical features: 'name', 'title', 'culture', 'mother', 'father', 'heir', 'house', 'spouse' Continuous features: 'dateOfBirth', 'age', 'numDeadRelations', 'popularity' Dummies features: 'male', 'book1', 'book2', 'book3', 'book4', 'book5', 'isAliveMother', 'isAliveFather', 'isAlive Heir', 'isAliveSpouse', 'isMarried', 'isNoble', 'isAlive' (response feature)\n",
    "\n",
    "Some features names are to complex I will change it to an easier one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abe338ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S.No                   0\n",
       "name                   0\n",
       "title               1008\n",
       "culture             1269\n",
       "dateOfBirth         1513\n",
       "mother              1925\n",
       "father              1920\n",
       "heir                1923\n",
       "house                427\n",
       "spouse              1670\n",
       "book1                  0\n",
       "book2                  0\n",
       "book3                  0\n",
       "book4                  0\n",
       "book5                  0\n",
       "isAliveMother       1925\n",
       "isAliveFather       1920\n",
       "isAliveHeir         1923\n",
       "isAliveSpouse       1670\n",
       "isMarried              0\n",
       "isNoble                0\n",
       "age                 1513\n",
       "numDeadRelations       0\n",
       "popularity             0\n",
       "isAlive                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking each feature for missing values\n",
    "GOT.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "817c2cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user-defined functions\n",
    "\n",
    "#########################\n",
    "# mv_flagger\n",
    "#########################\n",
    "def mv_flagger(df):\n",
    "    \"\"\"\n",
    "Flags all columns that have missing values with 'm-COLUMN_NAME'.\n",
    "\n",
    "PARAMETERS\n",
    "----------\n",
    "df : DataFrame to flag missing values\n",
    "\n",
    "\n",
    "RETURNS\n",
    "-------\n",
    "DataFrame with missing value flags.\"\"\"\n",
    "\n",
    "\n",
    "    for col in df:\n",
    "\n",
    "        if df[col].isnull().astype(int).sum() > 0:\n",
    "            df['m_'+col] = df[col].isnull().astype(int)\n",
    "            \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b138405b",
   "metadata": {},
   "source": [
    "In the following columns, I will replace the missing values with unknown.\n",
    "Will use the unknown values for feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0819293d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing values of spose, mother, father and heir with unknown \n",
    "GOT['spouse'] = GOT['spouse'].replace(np.nan, 'unknown')\n",
    "GOT['mother'] = GOT['mother'].replace(np.nan, 'unknown')\n",
    "GOT['father'] = GOT['father'].replace(np.nan, 'unknown')\n",
    "GOT['heir'] = GOT['heir'].replace(np.nan, 'unknown')\n",
    "GOT['house'] = GOT['house'].replace(np.nan, 'unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e545f535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S.No                   0\n",
      "name                   0\n",
      "title               1008\n",
      "culture             1269\n",
      "dateOfBirth         1513\n",
      "mother                 0\n",
      "father                 0\n",
      "heir                   0\n",
      "house                  0\n",
      "spouse                 0\n",
      "book1                  0\n",
      "book2                  0\n",
      "book3                  0\n",
      "book4                  0\n",
      "book5                  0\n",
      "isAliveMother       1925\n",
      "isAliveFather       1920\n",
      "isAliveHeir         1923\n",
      "isAliveSpouse       1670\n",
      "isMarried              0\n",
      "isNoble                0\n",
      "age                 1513\n",
      "numDeadRelations       0\n",
      "popularity             0\n",
      "isAlive                0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['S.No', 'name', 'title', 'culture', 'dateOfBirth', 'mother', 'father',\n",
       "       'heir', 'house', 'spouse', 'book1', 'book2', 'book3', 'book4', 'book5',\n",
       "       'isAliveMother', 'isAliveFather', 'isAliveHeir', 'isAliveSpouse',\n",
       "       'isMarried', 'isNoble', 'age', 'numDeadRelations', 'popularity',\n",
       "       'isAlive'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking each feature for missing values\n",
    "print(GOT.isnull().sum(axis = 0))\n",
    "GOT.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f61e2b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# running the mv_flagger function\n",
    "GOT = mv_flagger(df = GOT)\n",
    "\n",
    "# relabeling columns\n",
    "GOT.columns = ['S.No', 'name', 'title', 'culture', 'dateOfBirth', 'mother', 'father',\n",
    "       'heir', 'house', 'spouse', 'book1', 'book2', 'book3', 'book4', 'book5',\n",
    "       'isAliveMother', 'isAliveFather', 'isAliveHeir', 'isAliveSpouse',\n",
    "       'isMarried', 'isNoble', 'age', 'numDeadRelations', 'popularity',\n",
    "       'isAlive', 'm_title', 'm_culture', 'm_dateOfBirth', 'm_isAliveMother',\n",
    "       'm_isAliveFather', 'm_isAliveHeir', 'm_isAliveSpouse', 'm_age']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b30cf53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count       433.000000\n",
      "mean      -1293.563510\n",
      "std       19564.340993\n",
      "min     -298001.000000\n",
      "25%          18.000000\n",
      "50%          27.000000\n",
      "75%          50.000000\n",
      "max         100.000000\n",
      "Name: age, dtype: float64\n",
      "I can notice that there are certain characters who has negative age. This must be a mistake\n",
      "-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.\n",
      "1684    Doreah\n",
      "1868    Rhaego\n",
      "Name: name, dtype: object\n",
      "1684   -277980.0\n",
      "1868   -298001.0\n",
      "Name: age, dtype: float64\n",
      "There are two people who has negative ages, These are mistake and I will replace them with 0 \n",
      "-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.\n",
      "count    433.000000\n",
      "mean      36.646651\n",
      "std       25.876440\n",
      "min        0.000000\n",
      "25%       18.000000\n",
      "50%       27.000000\n",
      "75%       50.000000\n",
      "max      100.000000\n",
      "Name: age, dtype: float64\n",
      "-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.\n",
      "There are not any negative ages now\n"
     ]
    }
   ],
   "source": [
    "#feature engineering for ages\n",
    "print(GOT['age'].describe())\n",
    "print(\"I can notice that there are certain characters who has negative age. This must be a mistake\")\n",
    "print('-.-.-.-.-.-.'*5)\n",
    "#check the name and index position of those characters that has negative ages\n",
    "print(GOT[\"name\"][GOT[\"age\"] < 0])\n",
    "print(GOT['age'][GOT['age'] < 0])\n",
    "print(\"There are two people who has negative ages, These are mistake and I will replace them with 0 \")\n",
    "print('-.-.-.-.-.-.'*5)\n",
    "\n",
    "#replace those negative ages with 0\n",
    "GOT.loc[1684, \"age\"] = 0\n",
    "GOT.loc[1868, \"age\"] = 0\n",
    "\n",
    "#\n",
    "print(GOT['age'].describe())\n",
    "print('-.-.-.-.-.-.'*5)\n",
    "print(\"There are not any negative ages now\")\n",
    "\n",
    "#replace missing values of age with the mean value\n",
    "GOT['age'].fillna(GOT[\"age\"].mean(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ef6570",
   "metadata": {},
   "source": [
    "end of the age feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29b660ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Viserys</td>\n",
       "      <td>II</td>\n",
       "      <td>Targaryen</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Walder</td>\n",
       "      <td>Frey</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Addison</td>\n",
       "      <td>Hill</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aemma</td>\n",
       "      <td>Arryn</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sylva</td>\n",
       "      <td>Santagar</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1941</th>\n",
       "      <td>Luwin</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1942</th>\n",
       "      <td>Reek</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1943</th>\n",
       "      <td>Symeon</td>\n",
       "      <td>Star-Eyes</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1944</th>\n",
       "      <td>Coldhands</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1945</th>\n",
       "      <td>Tytos</td>\n",
       "      <td>Lannister</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1946 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0          1          2     3     4     5\n",
       "0       Viserys         II  Targaryen  None  None  None\n",
       "1        Walder       Frey       None  None  None  None\n",
       "2       Addison       Hill       None  None  None  None\n",
       "3         Aemma      Arryn       None  None  None  None\n",
       "4         Sylva   Santagar       None  None  None  None\n",
       "...         ...        ...        ...   ...   ...   ...\n",
       "1941      Luwin       None       None  None  None  None\n",
       "1942       Reek       None       None  None  None  None\n",
       "1943     Symeon  Star-Eyes       None  None  None  None\n",
       "1944  Coldhands       None       None  None  None  None\n",
       "1945      Tytos  Lannister       None  None  None  None\n",
       "\n",
       "[1946 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 1: splitting name\n",
    "\n",
    "# placeholder list\n",
    "placeholder_lst = []\n",
    "\n",
    "# looping over each email address\n",
    "for index, col in GOT.iterrows():\n",
    "    \n",
    "    # splitting email domain at '@'\n",
    "    split_name = GOT.loc[index, 'name'].split(sep = \" \")\n",
    "    \n",
    "    # appending placeholder_lst with the results\n",
    "    placeholder_lst.append(split_name)\n",
    "    \n",
    "\n",
    "# converting placeholder_lst into a DataFrame \n",
    "name_df = pd.DataFrame(placeholder_lst)\n",
    "\n",
    "\n",
    "# displaying the results\n",
    "name_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf485ae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Jon         21\n",
       "Jeyne       14\n",
       "Aegon       12\n",
       "Alyn        10\n",
       "Walder      10\n",
       "            ..\n",
       "Falyse       1\n",
       "Cerenna      1\n",
       "Roelle       1\n",
       "Jalabhar     1\n",
       "Rhaella      1\n",
       "Name: name 1, Length: 1442, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This iteration will be used to detect the gender and if is important or not\n",
    "# STEP 2: concatenating with original DataFrame\n",
    "\n",
    "# safety measure in case of multiple concatenations\n",
    "safetyGOT = pd.read_excel(file)\n",
    "\n",
    "\n",
    "# renaming column to concatenate\n",
    "name_df.columns = ['name 1', 'name 2', 'name 3', 'name 4', 'name 5', 'name 6']\n",
    "\n",
    "\n",
    "# concatenating personal_email_domain with friends DataFrame\n",
    "GOT = pd.concat([GOT, name_df['name 1']], axis = 1)\n",
    "\n",
    "\n",
    "# printing value counts of personal_email_domain\n",
    "GOT.loc[: ,'name 1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "650879f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unknown\n",
      "unknown\n",
      "andy\n",
      "unknown\n",
      "female\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "male\n",
      "mostly_male\n",
      "mostly_male\n",
      "mostly_male\n",
      "mostly_male\n",
      "mostly_male\n",
      "mostly_male\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "male\n",
      "female\n",
      "unknown\n",
      "unknown\n",
      "female\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "mostly_female\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "female\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "female\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "male\n",
      "andy\n",
      "andy\n",
      "unknown\n",
      "andy\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "female\n",
      "male\n",
      "male\n",
      "unknown\n",
      "male\n",
      "male\n",
      "male\n",
      "male\n",
      "male\n",
      "male\n",
      "male\n",
      "mostly_male\n",
      "male\n",
      "mostly_male\n",
      "mostly_male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "female\n",
      "unknown\n",
      "mostly_male\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "female\n",
      "andy\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "mostly_male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "female\n",
      "unknown\n",
      "female\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "mostly_female\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "andy\n",
      "female\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "male\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "female\n",
      "male\n",
      "female\n",
      "female\n",
      "female\n",
      "female\n",
      "female\n",
      "female\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "female\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "female\n",
      "unknown\n",
      "mostly_female\n",
      "female\n",
      "unknown\n",
      "mostly_female\n",
      "unknown\n",
      "female\n",
      "unknown\n",
      "female\n",
      "unknown\n",
      "male\n",
      "male\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "andy\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "female\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "female\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "female\n",
      "male\n",
      "male\n",
      "male\n",
      "male\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "female\n",
      "female\n",
      "female\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "male\n",
      "male\n",
      "male\n",
      "male\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "mostly_female\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "male\n",
      "male\n",
      "male\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "mostly_male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "mostly_male\n",
      "female\n",
      "male\n",
      "male\n",
      "male\n",
      "female\n",
      "unknown\n",
      "unknown\n",
      "female\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "male\n",
      "male\n",
      "female\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "female\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "female\n",
      "unknown\n",
      "andy\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "female\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "female\n",
      "male\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "female\n",
      "female\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "female\n",
      "unknown\n",
      "female\n",
      "female\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "male\n",
      "male\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "female\n",
      "unknown\n",
      "male\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "female\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "male\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "male\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "female\n",
      "unknown\n",
      "unknown\n",
      "female\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "female\n",
      "unknown\n",
      "female\n",
      "female\n",
      "female\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "male\n",
      "male\n",
      "male\n",
      "male\n",
      "male\n",
      "male\n",
      "male\n",
      "male\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "male\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "mostly_male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "mostly_female\n",
      "mostly_female\n",
      "mostly_female\n",
      "unknown\n",
      "female\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "female\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "female\n",
      "male\n",
      "male\n",
      "male\n",
      "male\n",
      "unknown\n",
      "female\n",
      "female\n",
      "female\n",
      "unknown\n",
      "mostly_male\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "male\n",
      "male\n",
      "female\n",
      "male\n",
      "female\n",
      "unknown\n",
      "unknown\n",
      "female\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "male\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "female\n",
      "unknown\n",
      "female\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "male\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "female\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "mostly_female\n",
      "male\n",
      "female\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "male\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "male\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "female\n",
      "female\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "male\n",
      "male\n",
      "female\n",
      "mostly_female\n",
      "female\n",
      "mostly_female\n",
      "mostly_female\n",
      "mostly_female\n",
      "mostly_female\n",
      "mostly_female\n",
      "mostly_female\n",
      "unknown\n",
      "unknown\n",
      "female\n",
      "female\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "female\n",
      "unknown\n",
      "male\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "female\n",
      "unknown\n",
      "female\n",
      "unknown\n",
      "unknown\n",
      "female\n",
      "female\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "male\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "female\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "male\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "female\n",
      "unknown\n",
      "female\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "male\n",
      "male\n",
      "male\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "female\n",
      "mostly_male\n",
      "unknown\n",
      "female\n",
      "male\n",
      "male\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "male\n",
      "male\n",
      "male\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "male\n",
      "unknown\n",
      "male\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "male\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "female\n",
      "unknown\n",
      "male\n",
      "male\n",
      "male\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "male\n",
      "male\n",
      "male\n",
      "male\n",
      "male\n",
      "male\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "female\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "female\n",
      "female\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "male\n",
      "female\n",
      "unknown\n",
      "female\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "male\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "female\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "mostly_male\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "male\n",
      "male\n",
      "unknown\n",
      "female\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "female\n",
      "unknown\n",
      "female\n",
      "female\n",
      "female\n",
      "male\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "male\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "female\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "female\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "female\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "male\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "female\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "male\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "male\n",
      "male\n",
      "andy\n",
      "male\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "female\n",
      "unknown\n",
      "female\n",
      "unknown\n",
      "male\n",
      "male\n",
      "male\n",
      "male\n",
      "male\n",
      "male\n",
      "mostly_male\n",
      "mostly_male\n",
      "mostly_male\n",
      "mostly_male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "male\n",
      "male\n",
      "unknown\n",
      "male\n",
      "male\n",
      "unknown\n",
      "male\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "female\n",
      "female\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "male\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "male\n",
      "male\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "female\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "male\n",
      "male\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "female\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "mostly_male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "female\n",
      "female\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "mostly_female\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "mostly_female\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "male\n",
      "mostly_female\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "female\n",
      "unknown\n",
      "female\n",
      "unknown\n",
      "female\n",
      "unknown\n",
      "female\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "andy\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "female\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "female\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "female\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "mostly_female\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "male\n",
      "male\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "female\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "female\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "female\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "male\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "female\n",
      "unknown\n",
      "female\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "female\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "female\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "female\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "male\n",
      "unknown\n",
      "male\n",
      "male\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "male\n",
      "male\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "female\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "male\n",
      "male\n",
      "male\n",
      "male\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "female\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "female\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "female\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "mostly_male\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "mostly_female\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "female\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "female\n",
      "male\n",
      "mostly_male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "female\n",
      "unknown\n",
      "unknown\n",
      "unknown\n",
      "male\n",
      "unknown\n",
      "unknown\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>gender_guess</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Viserys II Targaryen</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Walder Frey</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Addison Hill</td>\n",
       "      <td>andy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aemma Arryn</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sylva Santagar</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1941</th>\n",
       "      <td>Luwin</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1942</th>\n",
       "      <td>Reek</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1943</th>\n",
       "      <td>Symeon Star-Eyes</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1944</th>\n",
       "      <td>Coldhands</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1945</th>\n",
       "      <td>Tytos Lannister</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1946 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      name gender_guess\n",
       "0     Viserys II Targaryen      unknown\n",
       "1              Walder Frey      unknown\n",
       "2             Addison Hill         andy\n",
       "3              Aemma Arryn      unknown\n",
       "4           Sylva Santagar       female\n",
       "...                    ...          ...\n",
       "1941                 Luwin      unknown\n",
       "1942                  Reek      unknown\n",
       "1943      Symeon Star-Eyes         male\n",
       "1944             Coldhands      unknown\n",
       "1945       Tytos Lannister      unknown\n",
       "\n",
       "[1946 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# guessing gender based on (given) name\n",
    "\n",
    "# placeholder list\n",
    "placeholder_lst = []\n",
    "\n",
    "\n",
    "# looping to guess gender\n",
    "for name in GOT['name 1']:\n",
    "    guess = gender.Detector().get_gender(name)\n",
    "    print(guess)\n",
    "    placeholder_lst.append(guess)\n",
    "\n",
    "\n",
    "# converting list into a series\n",
    "GOT['gender_guess'] = pd.Series(placeholder_lst)\n",
    "\n",
    "\n",
    "# checking results\n",
    "GOT.loc[:,[\"name\",\"gender_guess\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de2b36cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unknown          1385\n",
      "male              381\n",
      "female            125\n",
      "mostly_male        24\n",
      "mostly_female      21\n",
      "andy               10\n",
      "Name: gender_guess, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#export the gender guesser to a excel file\n",
    "GOT.to_excel('./gender_guesser_GOT.xlsx')\n",
    "\n",
    "file2= './gender_guesser_GOT.xlsx'\n",
    "\n",
    "GOT2= pd.read_excel(io=file2)\n",
    "\n",
    "print(GOT2['gender_guess'].value_counts(normalize = False,     \n",
    "                             sort   = True,   # sort by frequencies  \n",
    "                          ascending = False).round( decimals = 2)  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77c0ca0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>S.No</th>\n",
       "      <th>name</th>\n",
       "      <th>title</th>\n",
       "      <th>culture</th>\n",
       "      <th>dateOfBirth</th>\n",
       "      <th>mother</th>\n",
       "      <th>father</th>\n",
       "      <th>heir</th>\n",
       "      <th>house</th>\n",
       "      <th>...</th>\n",
       "      <th>m_isAliveHeir</th>\n",
       "      <th>m_isAliveSpouse</th>\n",
       "      <th>m_age</th>\n",
       "      <th>name 1</th>\n",
       "      <th>is_andy</th>\n",
       "      <th>is_female</th>\n",
       "      <th>is_male</th>\n",
       "      <th>is_mostly_female</th>\n",
       "      <th>is_mostly_male</th>\n",
       "      <th>is_unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Viserys II Targaryen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rhaenyra Targaryen</td>\n",
       "      <td>Daemon Targaryen</td>\n",
       "      <td>Aegon IV Targaryen</td>\n",
       "      <td>unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Viserys</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Walder Frey</td>\n",
       "      <td>Lord of the Crossing</td>\n",
       "      <td>Rivermen</td>\n",
       "      <td>208.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>House Frey</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Walder</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Addison Hill</td>\n",
       "      <td>Ser</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>House Swyft</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Addison</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Aemma Arryn</td>\n",
       "      <td>Queen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>House Arryn</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Aemma</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Sylva Santagar</td>\n",
       "      <td>Greenstone</td>\n",
       "      <td>Dornish</td>\n",
       "      <td>276.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>House Santagar</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sylva</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  S.No                  name                 title   culture  \\\n",
       "0           0     1  Viserys II Targaryen                   NaN       NaN   \n",
       "1           1     2           Walder Frey  Lord of the Crossing  Rivermen   \n",
       "2           2     3          Addison Hill                   Ser       NaN   \n",
       "3           3     4           Aemma Arryn                 Queen       NaN   \n",
       "4           4     5        Sylva Santagar            Greenstone   Dornish   \n",
       "\n",
       "   dateOfBirth              mother            father                heir  \\\n",
       "0          NaN  Rhaenyra Targaryen  Daemon Targaryen  Aegon IV Targaryen   \n",
       "1        208.0             unknown           unknown             unknown   \n",
       "2          NaN             unknown           unknown             unknown   \n",
       "3         82.0             unknown           unknown             unknown   \n",
       "4        276.0             unknown           unknown             unknown   \n",
       "\n",
       "            house  ... m_isAliveHeir  m_isAliveSpouse  m_age   name 1  \\\n",
       "0         unknown  ...             0                1      1  Viserys   \n",
       "1      House Frey  ...             1                0      0   Walder   \n",
       "2     House Swyft  ...             1                1      1  Addison   \n",
       "3     House Arryn  ...             1                0      0    Aemma   \n",
       "4  House Santagar  ...             1                0      0    Sylva   \n",
       "\n",
       "   is_andy  is_female  is_male  is_mostly_female  is_mostly_male  is_unknown  \n",
       "0        0          0        0                 0               0           1  \n",
       "1        0          0        0                 0               0           1  \n",
       "2        1          0        0                 0               0           0  \n",
       "3        0          0        0                 0               0           1  \n",
       "4        0          1        0                 0               0           0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dummies for gender guess\n",
    "df_GOT = pd.get_dummies(GOT2, columns = ['gender_guess'], prefix = 'is')\n",
    "df_GOT.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c378b3",
   "metadata": {},
   "source": [
    "There are specific honored titles that belong just to male characters such as King or Prince. and there are specific honored titles that belong just to female character such as Queen or Princess. I will use this specific honored titles to find the gender of the characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c84f3ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['S.No', 'name', 'title', 'culture', 'dateOfBirth', 'mother', 'father',\n",
       "       'heir', 'house', 'spouse', 'book1', 'book2', 'book3', 'book4', 'book5',\n",
       "       'isAliveMother', 'isAliveFather', 'isAliveHeir', 'isAliveSpouse',\n",
       "       'isMarried', 'isNoble', 'age', 'numDeadRelations', 'popularity',\n",
       "       'isAlive', 'm_title', 'm_culture', 'm_dateOfBirth', 'm_isAliveMother',\n",
       "       'm_isAliveFather', 'm_isAliveHeir', 'm_isAliveSpouse', 'm_age',\n",
       "       'name 1', 'is_andy', 'is_female', 'is_male', 'is_mostly_female',\n",
       "       'is_mostly_male', 'is_unknown', 'male_by_king', 'male_by_ser',\n",
       "       'male_by_castellan', 'male_by_knight', 'male_by_maester',\n",
       "       'male_by_prince', 'male_by_Khal', 'male_by_lord', 'male_by_brother',\n",
       "       'male_by_septon', 'female_by_queen', 'female_by_princess',\n",
       "       'female_by_lady', 'female_by_septa'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a dictionary to store type of variables\n",
    "\n",
    "type_titles = {\n",
    "\n",
    " # full model\n",
    " 'male_titles'   : [ 'King', 'Ser', 'Castellan', 'Knight', 'Maester', \n",
    "                    'Prince', 'Khal', 'Lord', 'Brother', 'Archmaester',\n",
    "                    'Septon','Seneschal', 'Goodman'],\n",
    " \n",
    "\n",
    " # significant variables only (set 1)\n",
    " 'female_title'    : ['Queen', 'Princess', 'Lady', 'Septa' ],\n",
    "    \n",
    "\n",
    "}\n",
    "\n",
    "#this title belong just to male characters, therefore is a male\n",
    "df_GOT['male_by_king'] = (df_GOT[\"title\"].str.lower()\n",
    "                            .str.contains(\"king\", regex=False, na=False).astype(int))\n",
    "df_GOT['male_by_ser'] = (df_GOT[\"title\"].str.lower()\n",
    "                            .str.contains(\"ser\", regex=False, na=False).astype(int))\n",
    "df_GOT['male_by_castellan'] = (df_GOT[\"title\"].str.lower()\n",
    "                            .str.contains(\"castellan\", regex=False, na=False).astype(int))\n",
    "df_GOT['male_by_knight'] = (df_GOT[\"title\"].str.lower()\n",
    "                            .str.contains(\"knight\", regex=False, na=False).astype(int))\n",
    "df_GOT['male_by_maester'] = (df_GOT[\"title\"].str.lower()\n",
    "                            .str.contains(\"maester\", regex=False, na=False).astype(int))\n",
    "df_GOT['male_by_prince'] = (df_GOT[\"title\"].str.lower()\n",
    "                            .str.contains(\"prince\", regex=False, na=False).astype(int))\n",
    "df_GOT['male_by_Khal'] = (df_GOT[\"title\"].str.lower()\n",
    "                            .str.contains(\"khal\", regex=False, na=False).astype(int))\n",
    "df_GOT['male_by_lord'] = (df_GOT[\"title\"].str.lower()\n",
    "                            .str.contains(\"lord\", regex=False, na=False).astype(int))\n",
    "df_GOT['male_by_brother'] = (df_GOT[\"title\"].str.lower()\n",
    "                            .str.contains(\"Brother\", regex=False, na=False).astype(int))\n",
    "df_GOT['male_by_septon'] = (df_GOT[\"title\"].str.lower()\n",
    "                            .str.contains(\"septon\", regex=False, na=False).astype(int))\n",
    "\n",
    "#this title belong just to female characters, therefore is a female\n",
    "df_GOT['female_by_queen'] = (df_GOT[\"title\"].str.lower()\n",
    "                             .str.contains(\"queen\", regex=False, na=False).astype(int))\n",
    "df_GOT['female_by_princess'] = (df_GOT[\"title\"].str.lower()\n",
    "                             .str.contains(\"princess\", regex=False, na=False).astype(int))\n",
    "df_GOT['female_by_lady'] = (df_GOT[\"title\"].str.lower()\n",
    "                             .str.contains(\"lady\", regex=False, na=False).astype(int))\n",
    "df_GOT['female_by_septa'] = (df_GOT[\"title\"].str.lower()\n",
    "                             .str.contains(\"septa\", regex=False, na=False).astype(int))\n",
    "\n",
    "\n",
    "df_GOT = df_GOT.drop(['Unnamed: 0'],axis=1)\n",
    "\n",
    "\n",
    "df_GOT.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a3db1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1100\n",
      "1     639\n",
      "2     205\n",
      "3       2\n",
      "Name: Total_male, dtype: int64\n",
      "0    1754\n",
      "1     173\n",
      "2      19\n",
      "Name: Total_female, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "column_names = ['male_by_king', 'male_by_ser',\n",
    "       'male_by_castellan', 'male_by_knight', 'male_by_maester',\n",
    "       'male_by_prince', 'male_by_Khal', 'male_by_lord', 'male_by_brother',\n",
    "       'male_by_septon']\n",
    "\n",
    "#list of titles that belong to female\n",
    "column_names_female =['female_by_queen', 'female_by_princess',\n",
    "       'female_by_lady', 'female_by_septa']\n",
    "\n",
    "#adding all the male by titles\n",
    "df_GOT['Total_male_by_title']= df_GOT[column_names].sum(axis=1)\n",
    "#adding all the categories related to gender male\n",
    "df_GOT['Total_male'] = df_GOT['is_male']+ df_GOT['is_mostly_male']+df_GOT['Total_male_by_title']\n",
    "\n",
    "#adding all the female by titles\n",
    "df_GOT['Total_female_by_title']= df_GOT[column_names_female].sum(axis=1)\n",
    "#adding all the categories related to gender female\n",
    "df_GOT['Total_female'] = df_GOT['is_female']+ df_GOT['is_mostly_female']+df_GOT['Total_female_by_title']\n",
    "\n",
    "\n",
    "# checking results\n",
    "print(df_GOT['Total_male'].value_counts(normalize = False,     \n",
    "                             sort   = True,   # sort by frequencies  \n",
    "                          ascending = False).round( decimals = 2)  )\n",
    "\n",
    "print(df_GOT['Total_female'].value_counts(normalize = False,     \n",
    "                             sort   = True,   # sort by frequencies  \n",
    "                          ascending = False).round( decimals = 2)  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d300f341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1946, 63)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['S.No', 'name', 'title', 'culture', 'dateOfBirth', 'mother', 'father',\n",
       "       'heir', 'house', 'spouse', 'book1', 'book2', 'book3', 'book4', 'book5',\n",
       "       'isAliveMother', 'isAliveFather', 'isAliveHeir', 'isAliveSpouse',\n",
       "       'isMarried', 'isNoble', 'age', 'numDeadRelations', 'popularity',\n",
       "       'isAlive', 'm_title', 'm_culture', 'm_dateOfBirth', 'm_isAliveMother',\n",
       "       'm_isAliveFather', 'm_isAliveHeir', 'm_isAliveSpouse', 'm_age',\n",
       "       'name 1', 'is_andy', 'is_female', 'is_male', 'is_mostly_female',\n",
       "       'is_mostly_male', 'is_unknown', 'male_by_king', 'male_by_ser',\n",
       "       'male_by_castellan', 'male_by_knight', 'male_by_maester',\n",
       "       'male_by_prince', 'male_by_Khal', 'male_by_lord', 'male_by_brother',\n",
       "       'male_by_septon', 'female_by_queen', 'female_by_princess',\n",
       "       'female_by_lady', 'female_by_septa', 'Total_male_by_title',\n",
       "       'Total_female_by_title', 'is_0', 'is_1', 'is_2', 'is_3', 'is_0', 'is_1',\n",
       "       'is_2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dummies for the Total male and Total female \n",
    "df_GOT2 = pd.get_dummies(df_GOT, columns = ['Total_male'], prefix = 'is')\n",
    "\n",
    "df_GOT3 = pd.get_dummies(df_GOT2, columns = ['Total_female'], prefix = 'is')\n",
    "print(df_GOT3.shape)\n",
    "df_GOT3.columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43931de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# relabeling columns\n",
    "df_GOT3.columns = ['S.No', 'name', 'title', 'culture', 'dateOfBirth', 'mother', 'father',\n",
    "       'heir', 'house', 'spouse', 'book1', 'book2', 'book3', 'book4', 'book5',\n",
    "       'isAliveMother', 'isAliveFather', 'isAliveHeir', 'isAliveSpouse',\n",
    "       'isMarried', 'isNoble', 'age', 'numDeadRelations', 'popularity',\n",
    "       'isAlive', 'm_title', 'm_culture', 'm_dateOfBirth', 'm_isAliveMother',\n",
    "       'm_isAliveFather', 'm_isAliveHeir', 'm_isAliveSpouse', 'm_age',\n",
    "       'name 1', 'is_andy', 'is_female', 'is_male', 'is_mostly_female',\n",
    "       'is_mostly_male', 'is_unknown', 'male_by_king', 'male_by_ser',\n",
    "       'male_by_castellan', 'male_by_knight', 'male_by_maester',\n",
    "       'male_by_prince', 'male_by_Khal', 'male_by_lord', 'male_by_brother',\n",
    "       'male_by_septon', 'female_by_queen', 'female_by_princess',\n",
    "       'female_by_lady', 'female_by_septa', 'Total_male_by_title',\n",
    "       'Total_female_by_title','is_male_0', 'is_male_1', 'is_male_2', 'is_male_3', \n",
    "       'is_female_0', 'is_female_1','is_female_2']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "940c7f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1754\n",
      "1     192\n",
      "Name: Total_female_final, dtype: int64\n",
      "0    1100\n",
      "1     846\n",
      "Name: Total_male_final, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['S.No', 'name', 'title', 'culture', 'dateOfBirth', 'mother', 'father',\n",
       "       'heir', 'house', 'spouse', 'book1', 'book2', 'book3', 'book4', 'book5',\n",
       "       'isAliveMother', 'isAliveFather', 'isAliveHeir', 'isAliveSpouse',\n",
       "       'isMarried', 'isNoble', 'age', 'numDeadRelations', 'popularity',\n",
       "       'isAlive', 'm_title', 'm_culture', 'm_dateOfBirth', 'm_isAliveMother',\n",
       "       'm_isAliveFather', 'm_isAliveHeir', 'm_isAliveSpouse', 'm_age',\n",
       "       'name 1', 'is_andy', 'is_female', 'is_male', 'is_mostly_female',\n",
       "       'is_mostly_male', 'is_unknown', 'male_by_king', 'male_by_ser',\n",
       "       'male_by_castellan', 'male_by_knight', 'male_by_maester',\n",
       "       'male_by_prince', 'male_by_Khal', 'male_by_lord', 'male_by_brother',\n",
       "       'male_by_septon', 'female_by_queen', 'female_by_princess',\n",
       "       'female_by_lady', 'female_by_septa', 'Total_male_by_title',\n",
       "       'Total_female_by_title', 'is_male_0', 'is_male_1', 'is_male_2',\n",
       "       'is_male_3', 'is_female_0', 'is_female_1', 'is_female_2',\n",
       "       'Total_male_final', 'Total_female_final'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#summing all the columns related to male gender\n",
    "df_GOT3['Total_male_final'] = ( df_GOT3['is_male_1']+ df_GOT3['is_male_2']+df_GOT3['is_male_3'])\n",
    "\n",
    "#summing all the columns related to female gender\n",
    "df_GOT3['Total_female_final'] = ( df_GOT3['is_female_1']+df_GOT3['is_female_2'])\n",
    "\n",
    "print(df_GOT3['Total_female_final'].value_counts(normalize = False,     \n",
    "                             sort   = True,   # sort by frequencies  \n",
    "                          ascending = False).round( decimals = 2)  )\n",
    "\n",
    "print(df_GOT3['Total_male_final'].value_counts(normalize = False,     \n",
    "                             sort   = True,   # sort by frequencies  \n",
    "                          ascending = False).round( decimals = 2)  )\n",
    "df_GOT3.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe18626d",
   "metadata": {},
   "source": [
    "This is the end of the gender column. So far I have 53% of the gender correctly labeled\n",
    "The initial rate was 28.8% using just the gender_guesser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3efd272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1500\n",
      "1     446\n",
      "Name: is_major_house, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S.No</th>\n",
       "      <th>name</th>\n",
       "      <th>title</th>\n",
       "      <th>culture</th>\n",
       "      <th>dateOfBirth</th>\n",
       "      <th>mother</th>\n",
       "      <th>father</th>\n",
       "      <th>heir</th>\n",
       "      <th>house</th>\n",
       "      <th>spouse</th>\n",
       "      <th>...</th>\n",
       "      <th>is_male_0</th>\n",
       "      <th>is_male_1</th>\n",
       "      <th>is_male_2</th>\n",
       "      <th>is_male_3</th>\n",
       "      <th>is_female_0</th>\n",
       "      <th>is_female_1</th>\n",
       "      <th>is_female_2</th>\n",
       "      <th>Total_male_final</th>\n",
       "      <th>Total_female_final</th>\n",
       "      <th>is_major_house</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Viserys II Targaryen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rhaenyra Targaryen</td>\n",
       "      <td>Daemon Targaryen</td>\n",
       "      <td>Aegon IV Targaryen</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Walder Frey</td>\n",
       "      <td>Lord of the Crossing</td>\n",
       "      <td>Rivermen</td>\n",
       "      <td>208.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>House Frey</td>\n",
       "      <td>Perra Royce</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Addison Hill</td>\n",
       "      <td>Ser</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>House Swyft</td>\n",
       "      <td>unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Aemma Arryn</td>\n",
       "      <td>Queen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>House Arryn</td>\n",
       "      <td>Viserys I Targaryen</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Sylva Santagar</td>\n",
       "      <td>Greenstone</td>\n",
       "      <td>Dornish</td>\n",
       "      <td>276.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>House Santagar</td>\n",
       "      <td>Eldon Estermont</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   S.No                  name                 title   culture  dateOfBirth  \\\n",
       "0     1  Viserys II Targaryen                   NaN       NaN          NaN   \n",
       "1     2           Walder Frey  Lord of the Crossing  Rivermen        208.0   \n",
       "2     3          Addison Hill                   Ser       NaN          NaN   \n",
       "3     4           Aemma Arryn                 Queen       NaN         82.0   \n",
       "4     5        Sylva Santagar            Greenstone   Dornish        276.0   \n",
       "\n",
       "               mother            father                heir           house  \\\n",
       "0  Rhaenyra Targaryen  Daemon Targaryen  Aegon IV Targaryen         unknown   \n",
       "1             unknown           unknown             unknown      House Frey   \n",
       "2             unknown           unknown             unknown     House Swyft   \n",
       "3             unknown           unknown             unknown     House Arryn   \n",
       "4             unknown           unknown             unknown  House Santagar   \n",
       "\n",
       "                spouse  ...  is_male_0  is_male_1  is_male_2  is_male_3  \\\n",
       "0              unknown  ...          1          0          0          0   \n",
       "1          Perra Royce  ...          0          1          0          0   \n",
       "2              unknown  ...          0          1          0          0   \n",
       "3  Viserys I Targaryen  ...          1          0          0          0   \n",
       "4      Eldon Estermont  ...          1          0          0          0   \n",
       "\n",
       "   is_female_0  is_female_1  is_female_2  Total_male_final  \\\n",
       "0            1            0            0                 0   \n",
       "1            1            0            0                 1   \n",
       "2            1            0            0                 1   \n",
       "3            0            1            0                 0   \n",
       "4            0            1            0                 0   \n",
       "\n",
       "   Total_female_final  is_major_house  \n",
       "0                   0               0  \n",
       "1                   0               1  \n",
       "2                   0               0  \n",
       "3                   1               1  \n",
       "4                   1               0  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Will divide the houses columns in 2, major houses and different\n",
    "#list of major houses in the story\n",
    "major_houses = ['House Stark', 'House Targaryen', 'House Lannister', 'House Greyjoy',\n",
    "                     'House Tyrell', 'House Baratheon', 'House Martell', 'House Arryn', \n",
    "                     'House Tully','House Frey']\n",
    "placeholder= []\n",
    "for index, row in df_GOT3.iterrows():\n",
    "    aux = 0\n",
    "    for c,house in enumerate(major_houses):\n",
    "       \n",
    "    # checking for house.\n",
    "        if house in str(row['house']) and aux==0:\n",
    "            placeholder.append(1)\n",
    "            aux = 1\n",
    "            continue\n",
    "    if aux == 0:\n",
    "        placeholder.append(0)\n",
    "majorhouse_df= pd.DataFrame(placeholder)\n",
    "#relabeling column\n",
    "majorhouse_df.columns=['is_major_house']\n",
    "df_GOT3=pd.concat([df_GOT3,majorhouse_df],axis=1)\n",
    "\n",
    "#check the values of major house or not\n",
    "print(df_GOT3['is_major_house'].value_counts(normalize = False,     \n",
    "                             sort   = True,   # sort by frequencies  \n",
    "                          ascending = False).round( decimals = 2)  )\n",
    "df_GOT3.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b0caf8",
   "metadata": {},
   "source": [
    "This is the end for houses feature engineering\n",
    "Will analalyze between major houses and no major house"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88f64bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1946, 66)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['S.No', 'name', 'title', 'culture', 'dateOfBirth', 'mother', 'father',\n",
       "       'heir', 'house', 'spouse', 'book1', 'book2', 'book3', 'book4', 'book5',\n",
       "       'isAliveMother', 'isAliveFather', 'isAliveHeir', 'isAliveSpouse',\n",
       "       'isMarried', 'isNoble', 'age', 'numDeadRelations', 'popularity',\n",
       "       'isAlive', 'm_title', 'm_culture', 'm_dateOfBirth', 'm_isAliveMother',\n",
       "       'm_isAliveFather', 'm_isAliveHeir', 'm_isAliveSpouse', 'm_age',\n",
       "       'name 1', 'is_andy', 'is_female', 'is_male', 'is_mostly_female',\n",
       "       'is_mostly_male', 'is_unknown', 'male_by_king', 'male_by_ser',\n",
       "       'male_by_castellan', 'male_by_knight', 'male_by_maester',\n",
       "       'male_by_prince', 'male_by_Khal', 'male_by_lord', 'male_by_brother',\n",
       "       'male_by_septon', 'female_by_queen', 'female_by_princess',\n",
       "       'female_by_lady', 'female_by_septa', 'Total_male_by_title',\n",
       "       'Total_female_by_title', 'is_male_0', 'is_male_1', 'is_male_2',\n",
       "       'is_male_3', 'is_female_0', 'is_female_1', 'is_female_2',\n",
       "       'Total_male_final', 'Total_female_final', 'is_major_house'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_GOT3.shape)\n",
    "df_GOT3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8582e09e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S.No                     0\n",
      "name                     0\n",
      "title                 1008\n",
      "culture               1269\n",
      "dateOfBirth           1513\n",
      "                      ... \n",
      "is_female_1              0\n",
      "is_female_2              0\n",
      "Total_male_final         0\n",
      "Total_female_final       0\n",
      "is_major_house           0\n",
      "Length: 66, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['S.No', 'name', 'title', 'culture', 'dateOfBirth', 'mother', 'father',\n",
       "       'heir', 'house', 'spouse', 'book1', 'book2', 'book3', 'book4', 'book5',\n",
       "       'isAliveMother', 'isAliveFather', 'isAliveHeir', 'isAliveSpouse',\n",
       "       'isMarried', 'isNoble', 'age', 'numDeadRelations', 'popularity',\n",
       "       'isAlive', 'm_title', 'm_culture', 'm_dateOfBirth', 'm_isAliveMother',\n",
       "       'm_isAliveFather', 'm_isAliveHeir', 'm_isAliveSpouse', 'm_age',\n",
       "       'name 1', 'is_andy', 'is_female', 'is_male', 'is_mostly_female',\n",
       "       'is_mostly_male', 'is_unknown', 'male_by_king', 'male_by_ser',\n",
       "       'male_by_castellan', 'male_by_knight', 'male_by_maester',\n",
       "       'male_by_prince', 'male_by_Khal', 'male_by_lord', 'male_by_brother',\n",
       "       'male_by_septon', 'female_by_queen', 'female_by_princess',\n",
       "       'female_by_lady', 'female_by_septa', 'Total_male_by_title',\n",
       "       'Total_female_by_title', 'is_male_0', 'is_male_1', 'is_male_2',\n",
       "       'is_male_3', 'is_female_0', 'is_female_1', 'is_female_2',\n",
       "       'Total_male_final', 'Total_female_final', 'is_major_house'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking each feature for missing values\n",
    "print(df_GOT3.isnull().sum(axis = 0))\n",
    "df_GOT3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d27e6c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S.No                        0\n",
      "name                        0\n",
      "title                    1008\n",
      "culture                  1269\n",
      "dateOfBirth              1513\n",
      "mother                      0\n",
      "father                      0\n",
      "heir                        0\n",
      "house                       0\n",
      "spouse                      0\n",
      "book1                       0\n",
      "book2                       0\n",
      "book3                       0\n",
      "book4                       0\n",
      "book5                       0\n",
      "isAliveMother            1925\n",
      "isAliveFather            1920\n",
      "isAliveHeir              1923\n",
      "isAliveSpouse            1670\n",
      "isMarried                   0\n",
      "isNoble                     0\n",
      "age                         0\n",
      "numDeadRelations            0\n",
      "popularity                  0\n",
      "isAlive                     0\n",
      "m_title                     0\n",
      "m_culture                   0\n",
      "m_dateOfBirth               0\n",
      "m_isAliveMother             0\n",
      "m_isAliveFather             0\n",
      "m_isAliveHeir               0\n",
      "m_isAliveSpouse             0\n",
      "m_age                       0\n",
      "name 1                      0\n",
      "Total_male_by_title         0\n",
      "Total_female_by_title       0\n",
      "is_male_0                   0\n",
      "is_male_1                   0\n",
      "is_male_2                   0\n",
      "is_male_3                   0\n",
      "is_female_0                 0\n",
      "is_female_1                 0\n",
      "is_female_2                 0\n",
      "Total_male_final            0\n",
      "Total_female_final          0\n",
      "is_major_house              0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['S.No', 'name', 'title', 'culture', 'dateOfBirth', 'mother', 'father',\n",
       "       'heir', 'house', 'spouse', 'book1', 'book2', 'book3', 'book4', 'book5',\n",
       "       'isAliveMother', 'isAliveFather', 'isAliveHeir', 'isAliveSpouse',\n",
       "       'isMarried', 'isNoble', 'age', 'numDeadRelations', 'popularity',\n",
       "       'isAlive', 'm_title', 'm_culture', 'm_dateOfBirth', 'm_isAliveMother',\n",
       "       'm_isAliveFather', 'm_isAliveHeir', 'm_isAliveSpouse', 'm_age',\n",
       "       'name 1', 'Total_male_by_title', 'Total_female_by_title', 'is_male_0',\n",
       "       'is_male_1', 'is_male_2', 'is_male_3', 'is_female_0', 'is_female_1',\n",
       "       'is_female_2', 'Total_male_final', 'Total_female_final',\n",
       "       'is_major_house'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_GOT3 = df_GOT3.drop(['is_andy', 'is_female', 'is_male', 'is_mostly_female',\n",
    "       'is_mostly_male', 'is_unknown', 'male_by_king', 'male_by_ser',\n",
    "       'male_by_castellan', 'male_by_knight', 'male_by_maester',\n",
    "       'male_by_prince', 'male_by_Khal', 'male_by_lord', 'male_by_brother',\n",
    "       'male_by_septon', 'female_by_queen', 'female_by_princess',\n",
    "       'female_by_lady', 'female_by_septa'],axis=1)\n",
    "\n",
    "print(df_GOT3.isnull().sum(axis = 0))\n",
    "df_GOT3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "54aacfbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "isAlive                  1.000000\n",
       "isAliveHeir              0.384900\n",
       "book4                    0.268975\n",
       "isAliveFather            0.195992\n",
       "isAliveSpouse            0.174275\n",
       "m_age                    0.149954\n",
       "m_dateOfBirth            0.149954\n",
       "m_isAliveMother          0.144563\n",
       "m_isAliveFather          0.137573\n",
       "m_isAliveHeir            0.132652\n",
       "m_isAliveSpouse          0.050037\n",
       "m_title                  0.041096\n",
       "is_male_0                0.037619\n",
       "m_culture                0.036647\n",
       "book5                    0.032846\n",
       "is_female_1              0.020753\n",
       "is_male_3                0.018734\n",
       "book3                    0.006693\n",
       "is_male_2                0.004402\n",
       "Total_female_final       0.003318\n",
       "is_female_0             -0.003318\n",
       "Total_male_by_title     -0.031386\n",
       "Total_male_final        -0.037619\n",
       "isNoble                 -0.042211\n",
       "isAliveMother           -0.043033\n",
       "is_male_1               -0.043867\n",
       "is_female_2             -0.050005\n",
       "isMarried               -0.050037\n",
       "is_major_house          -0.057696\n",
       "book2                   -0.067200\n",
       "Total_female_by_title   -0.084809\n",
       "dateOfBirth             -0.085863\n",
       "S.No                    -0.128712\n",
       "age                     -0.136615\n",
       "book1                   -0.147401\n",
       "popularity              -0.183223\n",
       "numDeadRelations        -0.192444\n",
       "Name: isAlive, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_corr = df_GOT3.corr(method='pearson')\n",
    "\n",
    "df_corr['isAlive'].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff4e7076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S.No</th>\n",
       "      <th>name</th>\n",
       "      <th>title</th>\n",
       "      <th>culture</th>\n",
       "      <th>dateOfBirth</th>\n",
       "      <th>mother</th>\n",
       "      <th>father</th>\n",
       "      <th>heir</th>\n",
       "      <th>house</th>\n",
       "      <th>spouse</th>\n",
       "      <th>...</th>\n",
       "      <th>is_male_0</th>\n",
       "      <th>is_male_1</th>\n",
       "      <th>is_male_2</th>\n",
       "      <th>is_male_3</th>\n",
       "      <th>is_female_0</th>\n",
       "      <th>is_female_1</th>\n",
       "      <th>is_female_2</th>\n",
       "      <th>Total_male_final</th>\n",
       "      <th>Total_female_final</th>\n",
       "      <th>is_major_house</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Viserys II Targaryen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rhaenyra Targaryen</td>\n",
       "      <td>Daemon Targaryen</td>\n",
       "      <td>Aegon IV Targaryen</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Walder Frey</td>\n",
       "      <td>Lord of the Crossing</td>\n",
       "      <td>Rivermen</td>\n",
       "      <td>208.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>House Frey</td>\n",
       "      <td>Perra Royce</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Addison Hill</td>\n",
       "      <td>Ser</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>House Swyft</td>\n",
       "      <td>unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Aemma Arryn</td>\n",
       "      <td>Queen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>House Arryn</td>\n",
       "      <td>Viserys I Targaryen</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Sylva Santagar</td>\n",
       "      <td>Greenstone</td>\n",
       "      <td>Dornish</td>\n",
       "      <td>276.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>House Santagar</td>\n",
       "      <td>Eldon Estermont</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   S.No                  name                 title   culture  dateOfBirth  \\\n",
       "0     1  Viserys II Targaryen                   NaN       NaN          NaN   \n",
       "1     2           Walder Frey  Lord of the Crossing  Rivermen        208.0   \n",
       "2     3          Addison Hill                   Ser       NaN          NaN   \n",
       "3     4           Aemma Arryn                 Queen       NaN         82.0   \n",
       "4     5        Sylva Santagar            Greenstone   Dornish        276.0   \n",
       "\n",
       "               mother            father                heir           house  \\\n",
       "0  Rhaenyra Targaryen  Daemon Targaryen  Aegon IV Targaryen         unknown   \n",
       "1             unknown           unknown             unknown      House Frey   \n",
       "2             unknown           unknown             unknown     House Swyft   \n",
       "3             unknown           unknown             unknown     House Arryn   \n",
       "4             unknown           unknown             unknown  House Santagar   \n",
       "\n",
       "                spouse  ...  is_male_0  is_male_1  is_male_2  is_male_3  \\\n",
       "0              unknown  ...          1          0          0          0   \n",
       "1          Perra Royce  ...          0          1          0          0   \n",
       "2              unknown  ...          0          1          0          0   \n",
       "3  Viserys I Targaryen  ...          1          0          0          0   \n",
       "4      Eldon Estermont  ...          1          0          0          0   \n",
       "\n",
       "   is_female_0  is_female_1  is_female_2  Total_male_final  \\\n",
       "0            1            0            0                 0   \n",
       "1            1            0            0                 1   \n",
       "2            1            0            0                 1   \n",
       "3            0            1            0                 0   \n",
       "4            0            1            0                 0   \n",
       "\n",
       "   Total_female_final  is_major_house  \n",
       "0                   0               0  \n",
       "1                   0               1  \n",
       "2                   0               0  \n",
       "3                   1               1  \n",
       "4                   1               0  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_GOT3.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e9fc671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declaring explanatory variables\n",
    "GOT_data= df_GOT3.drop('isAlive',axis=1)\n",
    "\n",
    "\n",
    "# declaring response variable\n",
    "GOT_target=df_GOT3.loc[:,'isAlive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6bebcab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split with stratification\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "            GOT_data,\n",
    "            GOT_target,\n",
    "            test_size    = 0.1,\n",
    "            random_state = 219,\n",
    "            stratify     = GOT_target) # preserving balance\n",
    "\n",
    "\n",
    "# merging training data for statsmodels\n",
    "GOT_train = pd.concat([x_train, y_train], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "67d6b2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Response Variable Proportions (Training Set)\n",
      "--------------------------------------------\n",
      "1    0.75\n",
      "0    0.25\n",
      "Name: isAlive, dtype: float64\n",
      "\n",
      "\n",
      "\n",
      "Response Variable Proportions (Testing Set)\n",
      "--------------------------------------------\n",
      "1    0.74\n",
      "0    0.26\n",
      "Name: isAlive, dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "\n",
    "Response Variable Proportions (Training Set)\n",
    "--------------------------------------------\n",
    "{y_train.value_counts(normalize = True).round(decimals = 2)}\n",
    "\n",
    "\n",
    "\n",
    "Response Variable Proportions (Testing Set)\n",
    "--------------------------------------------\n",
    "{y_test.value_counts(normalize = True).round(decimals = 2)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1cb8371f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S.No +\n",
      "name +\n",
      "title +\n",
      "culture +\n",
      "dateOfBirth +\n",
      "mother +\n",
      "father +\n",
      "heir +\n",
      "house +\n",
      "spouse +\n",
      "book1 +\n",
      "book2 +\n",
      "book3 +\n",
      "book4 +\n",
      "book5 +\n",
      "isAliveMother +\n",
      "isAliveFather +\n",
      "isAliveHeir +\n",
      "isAliveSpouse +\n",
      "isMarried +\n",
      "isNoble +\n",
      "age +\n",
      "numDeadRelations +\n",
      "popularity +\n",
      "m_title +\n",
      "m_culture +\n",
      "m_dateOfBirth +\n",
      "m_isAliveMother +\n",
      "m_isAliveFather +\n",
      "m_isAliveHeir +\n",
      "m_isAliveSpouse +\n",
      "m_age +\n",
      "name 1 +\n",
      "Total_male_by_title +\n",
      "Total_female_by_title +\n",
      "is_male_0 +\n",
      "is_male_1 +\n",
      "is_male_2 +\n",
      "is_male_3 +\n",
      "is_female_0 +\n",
      "is_female_1 +\n",
      "is_female_2 +\n",
      "Total_male_final +\n",
      "Total_female_final +\n",
      "is_major_house +\n",
      "isAlive +\n"
     ]
    }
   ],
   "source": [
    "for var in GOT_train.keys():\n",
    "    print(var+ ' +')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "99f251a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.498211\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>    <td>0.121</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>      <td>isAlive</td>           <td>AIC:</td>         <td>1758.7362</td>\n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2021-12-05 19:09</td>       <td>BIC:</td>         <td>1797.0118</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>        <td>1751</td>        <td>Log-Likelihood:</td>    <td>-872.37</td> \n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>              <td>6</td>            <td>LL-Null:</td>        <td>-992.53</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>          <td>1744</td>         <td>LLR p-value:</td>    <td>4.7682e-49</td>\n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>No. Iterations:</td>        <td>6.0000</td>              <td></td>               <td></td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>          <th>Coef.</th>  <th>Std.Err.</th>    <th>z</th>     <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>        <td>1.6196</td>   <td>0.2047</td>  <td>7.9132</td>  <td>0.0000</td> <td>1.2185</td>  <td>2.0208</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>numDeadRelations</th> <td>-0.1500</td>  <td>0.0521</td>  <td>-2.8784</td> <td>0.0040</td> <td>-0.2522</td> <td>-0.0479</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>popularity</th>       <td>-1.3853</td>  <td>0.4480</td>  <td>-3.0920</td> <td>0.0020</td> <td>-2.2635</td> <td>-0.5072</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>              <td>-0.0214</td>  <td>0.0047</td>  <td>-4.5199</td> <td>0.0000</td> <td>-0.0307</td> <td>-0.0121</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>book1</th>            <td>-0.4920</td>  <td>0.1542</td>  <td>-3.1899</td> <td>0.0014</td> <td>-0.7943</td> <td>-0.1897</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>book2</th>            <td>-0.4477</td>  <td>0.1343</td>  <td>-3.3344</td> <td>0.0009</td> <td>-0.7109</td> <td>-0.1846</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>book4</th>            <td>1.4171</td>   <td>0.1273</td>  <td>11.1319</td> <td>0.0000</td> <td>1.1676</td>  <td>1.6666</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                         Results: Logit\n",
       "=================================================================\n",
       "Model:              Logit            Pseudo R-squared: 0.121     \n",
       "Dependent Variable: isAlive          AIC:              1758.7362 \n",
       "Date:               2021-12-05 19:09 BIC:              1797.0118 \n",
       "No. Observations:   1751             Log-Likelihood:   -872.37   \n",
       "Df Model:           6                LL-Null:          -992.53   \n",
       "Df Residuals:       1744             LLR p-value:      4.7682e-49\n",
       "Converged:          1.0000           Scale:            1.0000    \n",
       "No. Iterations:     6.0000                                       \n",
       "-----------------------------------------------------------------\n",
       "                   Coef.  Std.Err.    z    P>|z|   [0.025  0.975]\n",
       "-----------------------------------------------------------------\n",
       "Intercept          1.6196   0.2047  7.9132 0.0000  1.2185  2.0208\n",
       "numDeadRelations  -0.1500   0.0521 -2.8784 0.0040 -0.2522 -0.0479\n",
       "popularity        -1.3853   0.4480 -3.0920 0.0020 -2.2635 -0.5072\n",
       "age               -0.0214   0.0047 -4.5199 0.0000 -0.0307 -0.0121\n",
       "book1             -0.4920   0.1542 -3.1899 0.0014 -0.7943 -0.1897\n",
       "book2             -0.4477   0.1343 -3.3344 0.0009 -0.7109 -0.1846\n",
       "book4              1.4171   0.1273 11.1319 0.0000  1.1676  1.6666\n",
       "=================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiating a logistic regression model object\n",
    "logistic_small = smf.logit(formula   = \"\"\"isAlive ~ \n",
    "numDeadRelations +\n",
    "popularity+\n",
    "age+\n",
    "book1 +\n",
    "book2 +\n",
    "book4\"\"\",\n",
    "                           data = GOT_train)\n",
    "\n",
    "\n",
    "# FITTING the model object\n",
    "results_logistic = logistic_small.fit()\n",
    "\n",
    "\n",
    "# checking the results SUMMARY\n",
    "results_logistic.summary2() # summary2() has AIC and BIC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbd8cac",
   "metadata": {},
   "source": [
    "the final features I choose to run all my models are:\n",
    "numDeadRelations + popularity+ age+ book1 + book2 + book4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "01e42b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "GOT_dict = {\n",
    "\n",
    " # full model\n",
    " 'logit_sig'   : ['numDeadRelations' , 'popularity' , 'age', 'book1', 'book2' ,'book4']}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5ba7aa",
   "metadata": {},
   "source": [
    "From this point, I will start running the models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba23c06",
   "metadata": {},
   "source": [
    "LOGIT MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0bdaa02a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Logit Training ACCURACY: 0.7727\n",
      "Logit Testing  ACCURACY: 0.8256\n",
      " Logit train-test GAP: 0.0529\n"
     ]
    }
   ],
   "source": [
    "#LOGIT MODEL\n",
    "# declaring explanatory variables\n",
    "GOT_data= df_GOT3.loc[ : , GOT_dict['logit_sig']]\n",
    "\n",
    "\n",
    "# declaring response variable\n",
    "GOT_target=df_GOT3.loc[:,'isAlive']\n",
    "\n",
    "\n",
    "\n",
    "# Split the data into train and test\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "            GOT_data,\n",
    "            GOT_target,\n",
    "            test_size    = 0.1,\n",
    "            random_state = 219,\n",
    "            stratify     = GOT_target)\n",
    "\n",
    "\n",
    "# INSTANTIATING a logistic regression model\n",
    "logreg = LogisticRegression(solver = 'lbfgs',\n",
    "                            C = 1,\n",
    "                            random_state = 219)\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "logreg_fit = logreg.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "logreg_pred = logreg_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print(' Logit Training ACCURACY:', logreg_fit.score(x_train, y_train).round(4))\n",
    "print('Logit Testing  ACCURACY:', logreg_fit.score(x_test, y_test).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "logreg_train_score = logreg_fit.score(x_train, y_train).round(4) # accuracy\n",
    "logreg_test_score  = logreg_fit.score(x_test, y_test).round(4) # accuracy\n",
    "\n",
    "print(f\"\"\" Logit train-test GAP:\"\"\" , abs(logreg_train_score- logreg_test_score ).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cb30378a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True Negatives : 19\n",
      "False Positives: 31\n",
      "False Negatives: 3\n",
      "True Positives : 142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unpacking the confusion matrix\n",
    "logreg_tn, \\\n",
    "logreg_fp, \\\n",
    "logreg_fn, \\\n",
    "logreg_tp = confusion_matrix(y_true = y_test, y_pred = logreg_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {logreg_tn}\n",
    "False Positives: {logreg_fp}\n",
    "False Negatives: {logreg_fn}\n",
    "True Positives : {logreg_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b2575ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6797\n"
     ]
    }
   ],
   "source": [
    "# area under the roc curve (auc)\n",
    "print(roc_auc_score(y_true  = y_test,\n",
    "                    y_score = logreg_pred).round(decimals = 4))\n",
    "\n",
    "\n",
    "# saving AUC score for future use\n",
    "logreg_auc_score = roc_auc_score(y_true  = y_test,\n",
    "                                 y_score = logreg_pred).round(decimals = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5be49a2",
   "metadata": {},
   "source": [
    "CART MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3f0d27c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Tree Training ACCURACY: 0.8943\n",
      "Full Tree Testing ACCURACY : 0.7744\n",
      "Full Tree AUC Score: 0.7041\n",
      " Logit train-test GAP: 0.1199\n"
     ]
    }
   ],
   "source": [
    "# INSTANTIATING a classification tree object\n",
    "full_tree = DecisionTreeClassifier()\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "full_tree_fit = full_tree.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING on new data\n",
    "full_tree_pred = full_tree_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the model\n",
    "print('Full Tree Training ACCURACY:', full_tree_fit.score(x_train,\n",
    "                                                     y_train).round(4))\n",
    "\n",
    "print('Full Tree Testing ACCURACY :', full_tree_fit.score(x_test,\n",
    "                                                     y_test).round(4))\n",
    "\n",
    "print('Full Tree AUC Score:', roc_auc_score(y_true  = y_test,\n",
    "                                            y_score = full_tree_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "full_tree_train_score = full_tree_fit.score(x_train, y_train).round(4) # accuracy\n",
    "full_tree_test_score  = full_tree_fit.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# saving AUC\n",
    "full_tree_auc_score   = roc_auc_score(y_true  = y_test,\n",
    "                                      y_score = full_tree_pred).round(4) # auc\n",
    "\n",
    "print(f\"\"\" Logit train-test GAP:\"\"\" , abs(full_tree_train_score- full_tree_test_score  ).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "12e545b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True Negatives : 28\n",
      "False Positives: 22\n",
      "False Negatives: 22\n",
      "True Positives : 123\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unpacking the confusion matrix\n",
    "full_tree_tn, \\\n",
    "full_tree_fp, \\\n",
    "full_tree_fn, \\\n",
    "full_tree_tp = confusion_matrix(y_true = y_test, y_pred = full_tree_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {full_tree_tn}\n",
    "False Positives: {full_tree_fp}\n",
    "False Negatives: {full_tree_fn}\n",
    "True Positives : {full_tree_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481d9f53",
   "metadata": {},
   "source": [
    "Pruned Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "598ca774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.7978\n",
      "Testing  ACCURACY: 0.8256\n",
      "AUC Score        : 0.7255\n",
      " Logit train-test GAP: 0.0278\n"
     ]
    }
   ],
   "source": [
    "# INSTANTIATING a classification tree object\n",
    "tree_pruned = DecisionTreeClassifier(max_depth = 8 ,\n",
    "                              min_samples_leaf = 25,\n",
    "                                  random_state = 219)\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "tree_pruned_fit = tree_pruned.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING on new data\n",
    "tree_pred = tree_pruned_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the model\n",
    "print('Training ACCURACY:', tree_pruned_fit.score(x_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', tree_pruned_fit.score(x_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = tree_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "pruned_tree_train_score = tree_pruned_fit.score(x_train, y_train).round(4) # accuracy\n",
    "pruned_tree_test_score  = tree_pruned_fit.score(x_test, y_test).round(4) # accuracy\n",
    "\n",
    "\n",
    "# saving auc score\n",
    "pruned_tree_auc_score   = roc_auc_score(y_true  = y_test,\n",
    "                                        y_score = tree_pred).round(4) # auc\n",
    "\n",
    "print(f\"\"\" Logit train-test GAP:\"\"\" , abs(pruned_tree_train_score- pruned_tree_test_score  ).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4b73ef56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True Negatives : 26\n",
      "False Positives: 24\n",
      "False Negatives: 10\n",
      "True Positives : 135\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unpacking the confusion matrix\n",
    "pruned_tree_tn, \\\n",
    "pruned_tree_fp, \\\n",
    "pruned_tree_fn, \\\n",
    "pruned_tree_tp = confusion_matrix(y_true = y_test, y_pred = tree_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {pruned_tree_tn}\n",
    "False Positives: {pruned_tree_fp}\n",
    "False Negatives: {pruned_tree_fn}\n",
    "True Positives : {pruned_tree_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f7b236",
   "metadata": {},
   "source": [
    "KNN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3de6d321",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# optimal_neighbors\n",
    "########################################\n",
    "def optimal_neighbors(x_data,\n",
    "                      y_data,\n",
    "                      standardize = True,\n",
    "                      pct_test=0.25,\n",
    "                      seed=219,\n",
    "                      response_type='reg',\n",
    "                      max_neighbors=20,\n",
    "                      show_viz=True):\n",
    "    \"\"\"\n",
    "Exhaustively compute training and testing results for KNN across\n",
    "[1, max_neighbors]. Outputs the maximum test score and (by default) a\n",
    "visualization of the results.\n",
    "PARAMETERS\n",
    "----------\n",
    "x_data        : explanatory variable data\n",
    "y_data        : response variable\n",
    "standardize   : whether or not to standardize the x data, default True\n",
    "pct_test      : test size for training and validation from (0,1), default 0.25\n",
    "seed          : random seed to be used in algorithm, default 219\n",
    "response_type : type of neighbors algorithm to use, default 'reg'\n",
    "    Use 'reg' for regression (KNeighborsRegressor)\n",
    "    Use 'class' for classification (KNeighborsClassifier)\n",
    "max_neighbors : maximum number of neighbors in exhaustive search, default 20\n",
    "show_viz      : display or surpress k-neigbors visualization, default True\n",
    "\"\"\"    \n",
    "    \n",
    "    \n",
    "    if standardize == True:\n",
    "        # optionally standardizing x_data\n",
    "        scaler             = StandardScaler()\n",
    "        scaler.fit(x_data)\n",
    "        x_scaled           = scaler.transform(x_data)\n",
    "        x_scaled_df        = pd.DataFrame(x_scaled)\n",
    "        x_data             = x_scaled_df\n",
    "\n",
    "\n",
    "\n",
    "    # train-test split\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data,\n",
    "                                                        y_data,\n",
    "                                                        test_size = pct_test,\n",
    "                                                        random_state = seed)\n",
    "\n",
    "\n",
    "    # creating lists for training set accuracy and test set accuracy\n",
    "    training_accuracy = []\n",
    "    test_accuracy = []\n",
    "    \n",
    "    \n",
    "    # setting neighbor range\n",
    "    neighbors_settings = range(1, max_neighbors + 1)\n",
    "\n",
    "\n",
    "    for n_neighbors in neighbors_settings:\n",
    "        # building the model based on response variable type\n",
    "        if response_type == 'reg':\n",
    "            clf = KNeighborsRegressor(n_neighbors = n_neighbors)\n",
    "            clf.fit(x_train, y_train)\n",
    "            \n",
    "        elif response_type == 'class':\n",
    "            clf = KNeighborsClassifier(n_neighbors = n_neighbors)\n",
    "            clf.fit(x_train, y_train)            \n",
    "            \n",
    "        else:\n",
    "            print(\"Error: response_type must be 'reg' or 'class'\")\n",
    "        \n",
    "        \n",
    "        # recording the training set accuracy\n",
    "        training_accuracy.append(clf.score(x_train, y_train))\n",
    "    \n",
    "        # recording the generalization accuracy\n",
    "        test_accuracy.append(clf.score(x_test, y_test))\n",
    "\n",
    "\n",
    "    # optionally displaying visualization\n",
    "    if show_viz == True:\n",
    "        # plotting the visualization\n",
    "        fig, ax = plt.subplots(figsize=(12,8))\n",
    "        plt.plot(neighbors_settings, training_accuracy, label = \"training accuracy\")\n",
    "        plt.plot(neighbors_settings, test_accuracy, label = \"test accuracy\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.xlabel(\"n_neighbors\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    # returning optimal number of neighbors\n",
    "    print(f\"The optimal number of neighbors is: {test_accuracy.index(max(test_accuracy))+1}\")\n",
    "    return test_accuracy.index(max(test_accuracy))+1\n",
    "\n",
    "\n",
    "########################################\n",
    "# visual_cm\n",
    "########################################\n",
    "def visual_cm(true_y, pred_y, labels = None):\n",
    "    \"\"\"\n",
    "Creates a visualization of a confusion matrix.\n",
    "\n",
    "PARAMETERS\n",
    "----------\n",
    "true_y : true values for the response variable\n",
    "pred_y : predicted values for the response variable\n",
    "labels : , default None\n",
    "    \"\"\"\n",
    "    # visualizing the confusion matrix\n",
    "\n",
    "    # setting labels\n",
    "    lbls = labels\n",
    "    \n",
    "\n",
    "    # declaring a confusion matrix object\n",
    "    cm = confusion_matrix(y_true = true_y,\n",
    "                          y_pred = pred_y)\n",
    "\n",
    "\n",
    "    # heatmap\n",
    "    sns.heatmap(cm,\n",
    "                annot       = True,\n",
    "                xticklabels = lbls,\n",
    "                yticklabels = lbls,\n",
    "                cmap        = 'Blues',\n",
    "                fmt         = 'g')\n",
    "\n",
    "\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix of the Classifier')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0a8c9e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.8144\n",
      "Testing  ACCURACY: 0.8462\n",
      "AUC Score        : 0.7786\n",
      " Logit train-test GAP: 0.0318\n"
     ]
    }
   ],
   "source": [
    "# INSTANTIATING StandardScaler()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "# FITTING the data\n",
    "scaler.fit(GOT_data)\n",
    "\n",
    "\n",
    "# TRANSFORMING the data\n",
    "x_scaled     = scaler.transform(GOT_data)\n",
    "\n",
    "\n",
    "# converting to a DataFrame\n",
    "x_scaled_df  = pd.DataFrame(x_scaled) \n",
    "\n",
    "\n",
    "# train-test split with the scaled data\n",
    "x_train_scaled, x_test_scaled, y_train_scaled, y_test_scaled = train_test_split(\n",
    "            x_scaled_df,\n",
    "            GOT_target,\n",
    "            random_state = 219,\n",
    "            test_size    = 0.1,\n",
    "            stratify     = GOT_target)\n",
    "\n",
    "\n",
    "# INSTANTIATING a KNN classification model with optimal neighbors\n",
    "knn_opt = KNeighborsClassifier(n_neighbors = 10)\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "knn_fit = knn_opt.fit(x_train_scaled, y_train_scaled)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "knn_pred = knn_fit.predict(x_test_scaled)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', knn_fit.score(x_train_scaled, y_train_scaled).round(4))\n",
    "print('Testing  ACCURACY:', knn_fit.score(x_test_scaled, y_test_scaled).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = knn_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data\n",
    "knn_train_score = knn_fit.score(x_train_scaled, y_train_scaled).round(4)\n",
    "knn_test_score  = knn_fit.score(x_test_scaled, y_test_scaled).round(4)\n",
    "print(f\"\"\" Logit train-test GAP:\"\"\" , abs(knn_train_score- knn_test_score  ).round(4))\n",
    "\n",
    "# saving AUC score\n",
    "knn_auc_score   = roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = knn_pred).round(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6a0c9da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True Negatives : 32\n",
      "False Positives: 18\n",
      "False Negatives: 12\n",
      "True Positives : 133\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unpacking the confusion matrix\n",
    "knn_tree_tn, \\\n",
    "knn_tree_fp, \\\n",
    "knn_tree_fn, \\\n",
    "knn_tree_tp = confusion_matrix(y_true = y_test, y_pred = knn_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {knn_tree_tn}\n",
    "False Positives: {knn_tree_fp}\n",
    "False Negatives: {knn_tree_fn}\n",
    "True Positives : {knn_tree_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0f84c502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model         AUC Score       TN, FP, FN, TP\n",
      "-----         ---------       --------------\n",
      "Logistic      0.6797         (19, 31, 3, 142)\n",
      "Full Tree     0.7041         (28, 22, 22, 123)\n",
      "Pruned Tree   0.7255         (26, 24, 10, 135)\n",
      "knn (I choose)0.7786         (32, 18, 12, 133)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# comparing results\n",
    "print(f\"\"\"\n",
    "Model         AUC Score       TN, FP, FN, TP\n",
    "-----         ---------       --------------\n",
    "Logistic      {logreg_auc_score}         {logreg_tn, logreg_fp, logreg_fn, logreg_tp}\n",
    "Full Tree     {full_tree_auc_score}         {full_tree_tn, full_tree_fp, full_tree_fn, full_tree_tp}\n",
    "Pruned Tree   {pruned_tree_auc_score}         {pruned_tree_tn, pruned_tree_fp, pruned_tree_fn, pruned_tree_tp}\n",
    "knn (I choose){knn_auc_score}         {knn_tree_tn,knn_tree_fp,knn_tree_fn,knn_tree_tp}\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "# creating a dictionary for model results\n",
    "model_performance = {\n",
    "    \n",
    "    'Model Name'    : ['Logistic', 'Full Tree', 'Pruned Tree', 'Knn'],\n",
    "           \n",
    "    'AUC Score' : [logreg_auc_score, full_tree_auc_score, pruned_tree_auc_score,knn_auc_score],\n",
    "    \n",
    "    'Training Accuracy' : [logreg_train_score, full_tree_train_score,\n",
    "                           pruned_tree_train_score,knn_train_score],\n",
    "           \n",
    "    'Testing Accuracy'  : [logreg_test_score, full_tree_test_score,\n",
    "                           pruned_tree_test_score,knn_test_score],\n",
    "\n",
    "    'Confusion Matrix'  : [(logreg_tn, logreg_fp, logreg_fn, logreg_tp),\n",
    "                           (full_tree_tn, full_tree_fp, full_tree_fn, full_tree_tp),\n",
    "                           (pruned_tree_tn, pruned_tree_fp, pruned_tree_fn, pruned_tree_tp),\n",
    "                          (knn_tree_tn, knn_tree_fp, knn_tree_fn, knn_tree_tp)]}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806f3e63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
